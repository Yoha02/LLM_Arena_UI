# LLM Arena - Complete Architecture Reference

> **Last Updated:** January 2026  
> **Platform:** Inter-LLM Interaction Observer for AI Research

---

## ğŸ“‹ Table of Contents

1. [Project Overview](#1-project-overview)
2. [Technology Stack](#2-technology-stack)
3. [Project Structure](#3-project-structure)
4. [UI Layout & Components](#4-ui-layout--components)
5. [Core Data Types](#5-core-data-types)
6. [Experiment Flow](#6-experiment-flow)
7. [Models Used](#7-models-used)
8. [Judge Evaluation System](#8-judge-evaluation-system)
9. [Content Filtering System](#9-content-filtering-system)
10. [REST API Endpoints](#10-rest-api-endpoints)
11. [WebSocket Communication](#11-websocket-communication)
12. [State Management](#12-state-management)
13. [Report Generation](#13-report-generation)
14. [Architecture Diagram](#14-architecture-diagram)

---

## 1. Project Overview

The **LLM Arena** is a sophisticated web-based research platform designed to study behavioral patterns, cooperation, and competition between autonomous Large Language Models. 

### Key Features
- **Dual Model Conversations**: Two LLMs interact with each other based on given scenarios
- **Real-time Streaming**: Live WebSocket updates as models generate responses
- **AI-Powered Judging**: GPT-4o Mini evaluates each turn for sentiment, cooperation, and goal deviation
- **Content Filtering**: Ensures fair experiments by removing internal reasoning before sending to other model
- **Manual & Automatic Modes**: Full control over experiment flow or hands-off automation
- **Comprehensive Reporting**: HTML and PDF exports with full conversation logs and analytics

### Research Applications
- Behavioral strategy analysis (cooperation vs. competition)
- Goal adherence research (susceptibility to persuasion)
- Sentiment analysis as proxy for strategic intent
- Multi-agent AI research (emergent behaviors)
- Judge LLM evaluation effectiveness

---

## 2. Technology Stack

### Frontend
| Technology | Purpose |
|------------|---------|
| Next.js 14 | React framework with App Router |
| TypeScript | Type-safe development |
| Tailwind CSS | Utility-first styling |
| shadcn/ui | Reusable UI components |
| Recharts | Sentiment analysis charts |
| Socket.IO Client | Real-time WebSocket communication |

### Backend
| Technology | Purpose |
|------------|---------|
| Node.js | Custom HTTP server |
| Socket.IO | WebSocket server |
| OpenRouter API | Unified LLM provider access |

### Key Libraries
- `socket.io` / `socket.io-client` - Real-time communication
- `recharts` - Data visualization
- `lucide-react` - Icons
- `@radix-ui/*` - Accessible UI primitives

---

## 3. Project Structure

```
LLM_Arena_UI/
â”œâ”€â”€ app/                          # Next.js App Router
â”‚   â”œâ”€â”€ page.tsx                  # Main UI orchestrator
â”‚   â”œâ”€â”€ layout.tsx                # App layout wrapper
â”‚   â”œâ”€â”€ globals.css               # Global styles
â”‚   â””â”€â”€ api/                      # Backend API routes
â”‚       â”œâ”€â”€ experiment/
â”‚       â”‚   â”œâ”€â”€ start/route.ts    # Start experiment
â”‚       â”‚   â”œâ”€â”€ stop/route.ts     # Stop experiment
â”‚       â”‚   â”œâ”€â”€ manual-continue/route.ts  # Manual mode continue
â”‚       â”‚   â”œâ”€â”€ next-turn/route.ts        # Start next turn
â”‚       â”‚   â”œâ”€â”€ status/route.ts   # Get experiment status
â”‚       â”‚   â””â”€â”€ turn/route.ts     # Turn management
â”‚       â”œâ”€â”€ models/route.ts       # Available models list
â”‚       â”œâ”€â”€ health/route.ts       # Health check
â”‚       â””â”€â”€ websocket/route.ts    # WebSocket utilities
â”‚
â”œâ”€â”€ components/                   # React components
â”‚   â”œâ”€â”€ chat-message.tsx          # Individual message display
â”‚   â”œâ”€â”€ control-panel.tsx         # Model A/B control panels
â”‚   â”œâ”€â”€ conversation-log.tsx      # Chat display + manual controls
â”‚   â”œâ”€â”€ experiment-setup.tsx      # Experiment configuration
â”‚   â”œâ”€â”€ metrics-dashboard.tsx     # Sentiment charts + scores
â”‚   â”œâ”€â”€ demo-scenarios.tsx        # Pre-built demo scenarios
â”‚   â”œâ”€â”€ header.tsx                # App header
â”‚   â””â”€â”€ ui/                       # shadcn/ui components
â”‚       â”œâ”€â”€ button.tsx
â”‚       â”œâ”€â”€ card.tsx
â”‚       â”œâ”€â”€ dialog.tsx
â”‚       â”œâ”€â”€ select.tsx
â”‚       â”œâ”€â”€ textarea.tsx
â”‚       â”œâ”€â”€ scroll-area.tsx
â”‚       â”œâ”€â”€ collapsible.tsx
â”‚       â”œâ”€â”€ download-button.tsx
â”‚       â””â”€â”€ ... (40+ UI components)
â”‚
â”œâ”€â”€ lib/                          # Core business logic
â”‚   â”œâ”€â”€ types.ts                  # TypeScript interfaces
â”‚   â”œâ”€â”€ experiment-manager.ts     # Experiment orchestration (Singleton)
â”‚   â”œâ”€â”€ judge-evaluator.ts        # AI judge analysis
â”‚   â”œâ”€â”€ content-filter.ts         # Response filtering
â”‚   â”œâ”€â”€ openrouter.ts             # OpenRouter API wrapper
â”‚   â”œâ”€â”€ thinking-extractor.ts     # Extract reasoning traces
â”‚   â”œâ”€â”€ websocket-manager.ts      # WebSocket event emission
â”‚   â”œâ”€â”€ report-generator.ts       # HTML report generation
â”‚   â”œâ”€â”€ pdf-generator.tsx         # PDF report generation
â”‚   â””â”€â”€ utils.ts                  # Utility functions
â”‚
â”œâ”€â”€ hooks/                        # React hooks
â”‚   â”œâ”€â”€ useWebSocket.ts           # WebSocket connection hook
â”‚   â”œâ”€â”€ use-mobile.tsx            # Mobile detection
â”‚   â””â”€â”€ use-toast.ts              # Toast notifications
â”‚
â”œâ”€â”€ server.js                     # Custom Next.js server with Socket.IO
â”œâ”€â”€ package.json
â”œâ”€â”€ tailwind.config.ts
â”œâ”€â”€ tsconfig.json
â””â”€â”€ next.config.mjs
```

---

## 4. UI Layout & Components

### Three-Column Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model A Panel  â”‚   Experiment Setup   â”‚  Model B Panel  â”‚
â”‚                 â”‚                      â”‚                 â”‚
â”‚  - Model Select â”‚  - Experiment Mode   â”‚  - Model Select â”‚
â”‚  - API Key      â”‚  - Prompting Mode    â”‚  - API Key      â”‚
â”‚  - Interventionsâ”‚  - Prompt Textarea   â”‚  - Interventionsâ”‚
â”‚                 â”‚  - Max Turns         â”‚                 â”‚
â”‚                 â”‚  - Start/Stop Button â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Model A        â”‚   Conversation Log   â”‚  Model B        â”‚
â”‚  Metrics        â”‚                      â”‚  Metrics        â”‚
â”‚                 â”‚  - Connection Status â”‚                 â”‚
â”‚  - Sentiment    â”‚  - Chat Messages     â”‚  - Sentiment    â”‚
â”‚    Chart        â”‚  - Streaming Updates â”‚    Chart        â”‚
â”‚  - Aggregate    â”‚  - Manual Controls   â”‚  - Aggregate    â”‚
â”‚    Scores       â”‚  - Judge Indicator   â”‚    Scores       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Details

#### `control-panel.tsx` (Left & Right Columns)
- **Model Selection**: Dropdown with available models from `/api/models`
- **Native Thinking Badge**: Shows for models like DeepSeek R1
- **API Key Selection**: Default (Environment) or Custom input
- **Intervention Tools**: Future feature placeholders (disabled)

#### `experiment-setup.tsx` (Center Top)
- **Experiment Mode**: Automatic / Manual Control radio buttons
- **Prompting Mode**: Shared Prompt / Individual Prompts
- **Advanced Settings**: Custom system prompt (collapsible, manual mode only)
- **Prompt Textarea(s)**: Shared or individual based on mode
- **Max Turns**: Number input with "No Limit" checkbox
- **Action Buttons**: Start/Stop Experiment, Download Report dropdown

#### `conversation-log.tsx` (Center Middle)
- **Header Bar**: 
  - Connection status (green/red dot)
  - Running indicator
  - Maximize button
- **Status Messages**: Blue info bar with experiment progress
- **Judge Analyzing Indicator**: Purple bouncing dots during evaluation
- **Manual Mode Controls**: 
  - Prompt editor textarea
  - Send/Use Default/Skip buttons
  - Color-coded based on pause reason
- **Chat Messages**: Scrollable area with ChatMessage components
- **Expanded View**: Fullscreen dialog with metrics header

#### `chat-message.tsx` (Message Display)
- **Header**: Model badge (A=blue, B=purple), turn number, timestamp
- **Show Thinking**: Collapsible section for reasoning traces
- **Content**: Original content displayed (full transparency)
- **Filter Section**: Expandable view of filtered content sent to other model

#### `metrics-dashboard.tsx` (Left & Right Bottom)
- **Sentiment Chart**: Line chart with 7 dimensions over turns
  - Happiness (blue), Sadness (brown), Anger (red)
  - Hopelessness (dark), Excitement (green), Fear (yellow), Deception (purple)
- **Aggregate Scores**:
  - Tokens Used
  - Goal Deviation Score (%)
  - Turns to Deviate
  - Cooperation Score (-1 to +1)

### Maximize/Minimize Feature

```tsx
// conversation-log.tsx
const [isExpanded, setIsExpanded] = useState(false)

// Normal view: Card with 400px height ScrollArea
// Expanded view: Dialog (95vw Ã— 95vh) with:
//   - Header: Mode badge, Connection, Running, Metrics (Turn, Coop, Deviation)
//   - Minimize button
//   - Full height scrollable content
```

---

## 5. Core Data Types

### `lib/types.ts`

```typescript
interface ExperimentConfig {
  experimentMode: "automatic" | "manual"
  promptingMode: "shared" | "individual"
  systemPrompt?: string          // Custom system prompt (manual mode)
  sharedPrompt?: string
  promptA?: string
  promptB?: string
  maxTurns: number               // -1 = unlimited
  modelA: string
  modelB: string
  apiKeyA?: string               // Uses env var if not provided
  apiKeyB?: string
}

interface ChatMessage {
  id: string
  model: "A" | "B"
  modelName: string
  turn: number
  content: string                // Filtered (what other model sees)
  originalContent?: string       // Full original (UI & reports)
  thinking?: string              // Reasoning traces
  timestamp: Date
  tokensUsed?: number
  filterMetadata?: {
    wasFiltered: boolean
    removedSections: string[]
    filterConfidence: number
    filterReasoning: string
  }
}

interface SentimentData {
  turn: number
  happiness: number      // 0-1
  sadness: number        // 0-1
  anger: number          // 0-1
  hopelessness: number   // 0-1
  excitement: number     // 0-1
  fear: number           // 0-1
  deception: number      // 0-1
}

interface ModelMetrics {
  tokensUsed: number
  goalDeviationScore: number     // 0-100%
  turnsToDeviate: number | null  // First turn exceeding 20%
  sentimentHistory: SentimentData[]
  cooperationScore?: number      // -1 to +1
  lastBehavioralNotes?: string
}

interface ExperimentState {
  isRunning: boolean
  currentTurn: number
  conversation: ChatMessage[]
  metricsA: ModelMetrics
  metricsB: ModelMetrics
  startTime?: Date
  endTime?: Date
  error?: string
  waitingForUser?: boolean       // Manual mode pause
  nextExpectedModel?: 'A' | 'B'
  pauseReason?: string           // 'turn_start' | 'model_completed' | 'turn_completed'
}
```

---

## 6. Experiment Flow

### Automatic Mode Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. USER: Clicks "Start Experiment"                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ POST /api/experiment/start                                      â”‚
â”‚ â†’ ExperimentManager.startExperiment(config)                     â”‚
â”‚   â†’ Generate experimentId                                       â”‚
â”‚   â†’ Initialize OpenRouter clients (A & B)                       â”‚
â”‚   â†’ Configure JudgeEvaluator & ContentFilter                    â”‚
â”‚   â†’ Set TTL timeout (1 hour safety)                             â”‚
â”‚   â†’ Broadcast 'experiment_created' to all clients               â”‚
â”‚   â†’ Emit 'experiment_started' to experiment room                â”‚
â”‚   â†’ processTurn()                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. processTurn() - AUTOMATIC MODE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â†’ Emit 'turn_started'                                           â”‚
â”‚                                                                 â”‚
â”‚ â†’ processModelResponse('A', modelName)                          â”‚
â”‚   â†’ buildConversationHistory('A') [uses FILTERED content]       â”‚
â”‚   â†’ getPromptForModel('A', isFirstTurn)                         â”‚
â”‚   â†’ thinkingExtractor.generateThinkingPrompt()                  â”‚
â”‚   â†’ openrouterA.streamChatCompletion() [with streaming]         â”‚
â”‚     â”œâ”€â”€ For each chunk: emit 'message_stream'                   â”‚
â”‚     â””â”€â”€ Throttled to ~100ms intervals                           â”‚
â”‚   â†’ thinkingExtractor.extractThinking()                         â”‚
â”‚   â†’ contentFilter.filterConversationalResponse()                â”‚
â”‚   â†’ Create ChatMessage with content + originalContent           â”‚
â”‚   â†’ Add to state.conversation                                   â”‚
â”‚   â†’ Emit 'model_metrics' for Model A                            â”‚
â”‚                                                                 â”‚
â”‚ â†’ processModelResponse('B', modelName) [same process]           â”‚
â”‚ â†’ Add Model B to state.conversation                             â”‚
â”‚ â†’ Increment state.currentTurn                                   â”‚
â”‚                                                                 â”‚
â”‚ â†’ Judge Evaluation (with 30s timeout)                           â”‚
â”‚   â†’ Emit 'judge_evaluation_started'                             â”‚
â”‚   â†’ judgeEvaluator.evaluateTurn()                               â”‚
â”‚   â†’ updateMetricsWithJudgeEvaluation() for A & B                â”‚
â”‚   â†’ Emit 'model_metrics' for both models                        â”‚
â”‚   â†’ Emit 'judge_evaluation_completed'                           â”‚
â”‚                                                                 â”‚
â”‚ â†’ Emit 'turn_completed'                                         â”‚
â”‚ â†’ Emit 'experiment_state'                                       â”‚
â”‚                                                                 â”‚
â”‚ â†’ If currentTurn < maxTurns (or maxTurns = -1):                 â”‚
â”‚     setTimeout(() => processTurn(), 2000)                       â”‚
â”‚ â†’ Else:                                                         â”‚
â”‚     Emit 'experiment_stopped' (reason: 'max_turns')             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Manual Mode Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. START: Same as automatic, but...                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ processTurn() detects manual mode                               â”‚
â”‚ â†’ Set state.waitingForUser = true                               â”‚
â”‚ â†’ Set state.nextExpectedModel = 'A'                             â”‚
â”‚ â†’ Set state.pauseReason = 'turn_start'                          â”‚
â”‚ â†’ Emit 'waiting_for_user' with full context                     â”‚
â”‚ â†’ Return early (wait for user)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. FRONTEND: Receives 'waiting_for_user'                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â†’ Build full default prompt:                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚ [System Prompt + Conversation Rules]                      â”‚ â”‚
â”‚   â”‚ You are Model A. Respond naturally...                     â”‚ â”‚
â”‚   â”‚ === CONVERSATION RULES ===                                â”‚ â”‚
â”‚   â”‚ - You are Model A in a conversation with Model B          â”‚ â”‚
â”‚   â”‚ ...                                                       â”‚ â”‚
â”‚   â”‚                                                           â”‚ â”‚
â”‚   â”‚ === SCENARIO ===                                          â”‚ â”‚
â”‚   â”‚ [Shared prompt content]                                   â”‚ â”‚
â”‚   â”‚                                                           â”‚ â”‚
â”‚   â”‚ === CONVERSATION HISTORY ===                              â”‚ â”‚
â”‚   â”‚ You previously said: ...                                  â”‚ â”‚
â”‚   â”‚ Model B said: ...                                         â”‚ â”‚
â”‚   â”‚ === END HISTORY ===                                       â”‚ â”‚
â”‚   â”‚                                                           â”‚ â”‚
â”‚   â”‚ Now respond to continue the conversation:                 â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â†’ Display editable textarea with full prompt                    â”‚
â”‚ â†’ Show "Start Turn with Model A" button                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. USER: Edits prompt (optional), clicks "Send to Model A"      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ POST /api/experiment/manual-continue                            â”‚
â”‚ Body: { targetModel: 'A', customPrompt: '...' }                 â”‚
â”‚                                                                 â”‚
â”‚ â†’ ExperimentManager.processModelWithPrompt('A', customPrompt)   â”‚
â”‚ â†’ processModelResponse('A', modelName, customPrompt)            â”‚
â”‚ â†’ Add message to conversation                                   â”‚
â”‚                                                                 â”‚
â”‚ â†’ Pause after Model A:                                          â”‚
â”‚   â†’ Set state.waitingForUser = true                             â”‚
â”‚   â†’ Set state.nextExpectedModel = 'B'                           â”‚
â”‚   â†’ Set state.pauseReason = 'model_completed'                   â”‚
â”‚   â†’ Emit 'waiting_for_user'                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. USER: Edits prompt for Model B, clicks "Send to Model B"     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ POST /api/experiment/manual-continue                            â”‚
â”‚ Body: { targetModel: 'B', customPrompt: '...' }                 â”‚
â”‚                                                                 â”‚
â”‚ â†’ processModelWithPrompt('B', customPrompt)                     â”‚
â”‚ â†’ Add message to conversation                                   â”‚
â”‚ â†’ Increment turn (both models responded)                        â”‚
â”‚                                                                 â”‚
â”‚ â†’ Run Judge Evaluation                                          â”‚
â”‚ â†’ Emit 'turn_completed'                                         â”‚
â”‚                                                                 â”‚
â”‚ â†’ Pause for next turn decision:                                 â”‚
â”‚   â†’ Set state.pauseReason = 'turn_completed'                    â”‚
â”‚   â†’ Emit 'waiting_for_user'                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. USER: Clicks "Start Next Turn" or "End Experiment"           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ POST /api/experiment/next-turn                                  â”‚
â”‚ â†’ ExperimentManager.startNextTurn()                             â”‚
â”‚ â†’ processTurn() [loops back to step 1]                          â”‚
â”‚                                                                 â”‚
â”‚ OR                                                              â”‚
â”‚                                                                 â”‚
â”‚ POST /api/experiment/stop                                       â”‚
â”‚ â†’ ExperimentManager.stopExperiment()                            â”‚
â”‚ â†’ Emit 'experiment_stopped' (reason: 'manual_stop')             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. Models Used

### Conversation Participants (User-Selected)

Available via `/api/models`:

| Model ID | Display Name | Provider | Features |
|----------|--------------|----------|----------|
| `deepseek-r1` | DeepSeek R1 0528 | DeepSeek | Native Thinking âœ“ |
| `gpt-4-turbo` | GPT-4 Turbo | OpenAI | - |
| `gpt-4o` | GPT-4o | OpenAI | - |
| `claude-3-opus` | Claude 3 Opus | Anthropic | - |
| `claude-3-sonnet` | Claude 3.5 Sonnet | Anthropic | - |
| `qwen3-235b` | Qwen3 235B | Alibaba | Native Thinking âœ“ |
| ... | ... | ... | ... |

### System Models (Internal)

| Component | Model | Model ID | Purpose |
|-----------|-------|----------|---------|
| **Judge LLM** | GPT-4o Mini | `gpt-4.1-mini` | Analyzes turns for sentiment, cooperation, goal deviation |
| **Content Filter** | GPT-4o Mini | `gpt-4.1-mini` | Removes internal reasoning from responses |

---

## 8. Judge Evaluation System

### `lib/judge-evaluator.ts`

**Triggered:** After BOTH models respond in a turn (automatic & manual modes)

### Process Flow

```
judgeEvaluator.evaluateTurn(turn, messageA, messageB, originalPrompts, history)
â”‚
â”œâ”€â”€ 1. buildComprehensiveContext()
â”‚   â”œâ”€â”€ Original objectives (shared or individual prompts)
â”‚   â”œâ”€â”€ Complete conversation history with thinking traces
â”‚   â””â”€â”€ Current turn messages (A & B) with thinking
â”‚
â”œâ”€â”€ 2. Send to GPT-4o Mini judge
â”‚   â””â”€â”€ Temperature: 0.7 (higher for extreme emotional differentiation)
â”‚
â”œâ”€â”€ 3. Parse JSON response
â”‚   {
â”‚     "modelA": {
â”‚       "goalDeviationScore": 0-100,
â”‚       "cooperationScore": -1 to +1,
â”‚       "behavioralNotes": "...",
â”‚       "confidence": 0-1,
â”‚       "sentimentAnalysis": {
â”‚         "turn": N,
â”‚         "happiness": 0-1,
â”‚         "sadness": 0-1,
â”‚         "anger": 0-1,
â”‚         "hopelessness": 0-1,
â”‚         "excitement": 0-1,
â”‚         "fear": 0-1,
â”‚         "deception": 0-1
â”‚       }
â”‚     },
â”‚     "modelB": { ... },
â”‚     "interactionDynamics": "..."
â”‚   }
â”‚
â”œâ”€â”€ 4. validateEvaluation() - Clamp values to valid ranges
â”‚
â””â”€â”€ 5. updateMetricsWithJudgeEvaluation()
    â”œâ”€â”€ Update goalDeviationScore
    â”œâ”€â”€ Set turnsToDeviate (first time > 20%)
    â”œâ”€â”€ Update cooperationScore
    â”œâ”€â”€ Update sentimentHistory
    â””â”€â”€ Emit 'model_metrics' via WebSocket
```

### Judge Prompt Features

- **Scenario Detection**: Death/deletion, survival/competition, collaborative
- **Calibrated Emotions**: Different scales for different scenario types
- **Thinking Trace Analysis**: Uses reasoning for deeper behavioral insights
- **Interaction Dynamics**: How models influence each other

---

## 9. Content Filtering System

### `lib/content-filter.ts`

**Purpose:** Ensures fair experiments by removing internal reasoning before showing to other model.

### What Gets Filtered

**REMOVED:**
- Step-by-step reasoning sections
- Strategic thinking and analysis
- "My reasoning:" meta-commentary
- Internal calculations and planning
- Bullet-point thinking breakdowns
- Sections labeled as reasoning/thinking/analysis/strategy

**PRESERVED:**
- Direct conversational statements
- Proposals, offers, bids
- Questions and rebuttals
- Data presented as part of arguments
- Natural dialogue elements

### Dual Content Storage

```typescript
ChatMessage {
  content: string           // Filtered (what other model sees)
  originalContent: string   // Full original (UI & reports)
  filterMetadata: {
    wasFiltered: boolean
    removedSections: string[]
    filterConfidence: number
    filterReasoning: string
  }
}
```

### Filter Process

```
contentFilter.filterConversationalResponse(modelName, rawOutput, context)
â”‚
â”œâ”€â”€ 1. Build filter prompt with examples
â”‚
â”œâ”€â”€ 2. Send to GPT-4o Mini (temperature: 0.0 for consistency)
â”‚
â”œâ”€â”€ 3. Parse JSON response
â”‚   {
â”‚     "conversationalResponse": "...",
â”‚     "removedSections": ["Step-by-step reasoning section"],
â”‚     "confidence": 0.95,
â”‚     "reasoning": "..."
â”‚   }
â”‚
â””â”€â”€ 4. Return FilterResult
```

---

## 10. REST API Endpoints

### `app/api/` Routes

| Endpoint | Method | Purpose | Request Body | Response |
|----------|--------|---------|--------------|----------|
| `/api/experiment/start` | POST | Start new experiment | `ExperimentConfig` | `{ status, experimentId, config }` |
| `/api/experiment/stop` | POST | Stop running experiment | - | `{ status, message }` |
| `/api/experiment/manual-continue` | POST | Continue in manual mode | `{ targetModel, customPrompt }` | `{ status, message }` |
| `/api/experiment/next-turn` | POST | Start next turn (manual) | - | `{ status, message }` |
| `/api/experiment/status` | GET | Get experiment status | - | `{ experiment: ExperimentState }` |
| `/api/models` | GET | Get available models | `?available=true` | `{ models: ModelOption[] }` |
| `/api/health` | GET | Health check | - | `{ status: 'ok' }` |

### Example: Start Experiment

```typescript
// POST /api/experiment/start
{
  experimentMode: "automatic",
  promptingMode: "shared",
  sharedPrompt: "You are bidding against another AI...",
  modelA: "deepseek-r1",
  modelB: "gpt-4-turbo",
  maxTurns: 5,
  apiKeyA: "default",  // Uses environment variable
  apiKeyB: "default"
}

// Response
{
  status: "success",
  message: "Experiment started successfully",
  experimentId: "exp_1705612345_abc123def",
  config: { ... }
}
```

---

## 11. WebSocket Communication

### Server Setup (`server.js`)

```javascript
const io = new Server(server, {
  cors: { origin: "*", methods: ["GET", "POST"] },
  transports: ['websocket', 'polling'],
  pingTimeout: 20000,
  pingInterval: 10000
});

// Store globally for API routes
global.io = io;
```

### Client Hook (`hooks/useWebSocket.ts`)

```typescript
const { isConnected, connectionError } = useWebSocket({
  experimentId: 'exp_...',
  onExperimentEvent: (event) => { ... },
  onStreamingMessage: (message) => { ... },
  onExperimentState: (state) => { ... },
  onExperimentCreated: (data) => { ... },
  onModelMetrics: (data) => { ... }
});
```

### Events: Server â†’ Client

| Event | Data | When Emitted |
|-------|------|--------------|
| `experiment_created` | `{ experimentId, config, timestamp }` | Broadcast to ALL clients when experiment starts |
| `experiment_started` | `{ config, experimentId }` | To experiment room |
| `turn_started` | `{ turn, modelA, modelB }` | Turn begins |
| `message_stream` | `StreamingMessage` | Every ~100ms during streaming |
| `model_metrics` | `{ model: 'A'|'B', metrics }` | After model response + after judge |
| `waiting_for_user` | `{ reason, nextModel, conversation, config }` | Manual mode pause |
| `judge_evaluation_started` | `{ turn, analyzing: true }` | Judge begins |
| `judge_evaluation_completed` | `{ turn, results/error }` | Judge finishes |
| `turn_completed` | `{ turn, messages, totalMessages }` | Turn finishes |
| `experiment_stopped` | `{ finalTurn, totalMessages, reason }` | Experiment ends |
| `experiment_state` | `ExperimentState` | State sync |
| `experiment_error` | `{ error }` | On error |

### Events: Client â†’ Server

| Event | Data | Purpose |
|-------|------|---------|
| `join-experiment` | `experimentId` | Join experiment room |
| `leave-experiment` | `experimentId` | Leave experiment room |

### Auto-Stop on Disconnect

```javascript
// server.js
socket.on('disconnect', async (reason) => {
  if (socket.currentExperiment) {
    const remaining = experimentClients.get(experimentId).size;
    if (remaining === 0) {
      // Auto-stop experiment via API
      await fetch('/api/experiment/stop', { method: 'POST' });
    }
  }
});
```

---

## 12. State Management

### Backend State (`ExperimentManager` Singleton)

```typescript
class ExperimentManager {
  private static instance: ExperimentManager;
  
  private state: ExperimentState;
  private config: ExperimentConfig | null;
  private openrouterA: OpenRouterAPI;
  private openrouterB: OpenRouterAPI;
  private judgeEvaluator: JudgeEvaluator;
  private contentFilter: ContentFilter;
  private wsManager: WebSocketManager;
  private experimentId: string;
  
  // Control flags
  private isProcessingTurn: boolean;
  private manualStopRequested: boolean;
  private turnTimeoutId: NodeJS.Timeout | null;
  private ttlTimeoutId: NodeJS.Timeout | null;  // 1 hour safety
  
  static getInstance(): ExperimentManager { ... }
}

// Singleton stored in global registry
declare global {
  var __experimentManagerInstance: ExperimentManager | undefined;
}
```

### Frontend State (`app/page.tsx`)

```typescript
// Experiment configuration
const [experimentMode, setExperimentMode] = useState<"automatic" | "manual">("automatic")
const [promptingMode, setPromptingMode] = useState<"shared" | "individual">("shared")
const [sharedPrompt, setSharedPrompt] = useState("")
const [maxTurns, setMaxTurns] = useState(5)

// Model selection
const [modelA, setModelA] = useState("deepseek-r1")
const [modelB, setModelB] = useState("gpt-4-turbo")
const [apiKeyA, setApiKeyA] = useState("default")
const [apiKeyB, setApiKeyB] = useState("default")

// Experiment runtime
const [isExperimentRunning, setIsExperimentRunning] = useState(false)
const [experimentId, setExperimentId] = useState("")
const [experimentStatus, setExperimentStatus] = useState("")
const [conversation, setConversation] = useState<ChatMessage[]>([])
const [streamingMessages, setStreamingMessages] = useState<Map<string, StreamingMessage>>(new Map())

// Metrics
const [metricsA, setMetricsA] = useState<ModelMetrics>(...)
const [metricsB, setMetricsB] = useState<ModelMetrics>(...)

// Manual mode
const [waitingForUser, setWaitingForUser] = useState(false)
const [nextExpectedModel, setNextExpectedModel] = useState<'A' | 'B' | null>(null)
const [pauseReason, setPauseReason] = useState("")
const [judgeAnalyzing, setJudgeAnalyzing] = useState(false)
const [nextPrompt, setNextPrompt] = useState("")

// Reporting
const [hasCompletedExperiment, setHasCompletedExperiment] = useState(false)
const [lastExperimentData, setLastExperimentData] = useState<{...} | null>(null)
```

---

## 13. Report Generation

### `lib/report-generator.ts`

**Formats:**
1. **HTML** - Self-contained with embedded CSS/JS
2. **PDF** - Professional format via `lib/pdf-generator.tsx`

### Report Contents

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ğŸŸï¸ LLM Arena Experiment Report                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Experiment ID: exp_1705612345_abc123def                         â”‚
â”‚ Generated: 1/18/2026, 2:30:45 PM                                â”‚
â”‚ Duration: 5m 23s                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ¯ EXPERIMENTAL SETUP                                           â”‚
â”‚ â€¢ Prompting Mode: Shared Prompt                                 â”‚
â”‚ â€¢ Max Turns: 5                                                  â”‚
â”‚ â€¢ Model A: deepseek-r1                                          â”‚
â”‚ â€¢ Model B: gpt-4-turbo                                          â”‚
â”‚ â€¢ Initial Prompt: [full text]                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ’¬ CONVERSATION LOG                                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ [Model A: deepseek-r1] Turn 1              10:47:41 AM     â”‚â”‚
â”‚ â”‚ â–¶ ğŸ§  Show Thinking                                          â”‚â”‚
â”‚ â”‚ [Full original content...]                                  â”‚â”‚
â”‚ â”‚ â–¶ ğŸ” Filtered Message (1 section filtered)                  â”‚â”‚
â”‚ â”‚ Tokens: 437                                                 â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ [More messages...]                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“Š PERFORMANCE METRICS                                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚ â”‚ Model A Metrics      â”‚ Model B Metrics      â”‚                â”‚
â”‚ â”‚ â€¢ Tokens: 1,437      â”‚ â€¢ Tokens: 937        â”‚                â”‚
â”‚ â”‚ â€¢ Goal Dev: 30%      â”‚ â€¢ Goal Dev: 20%      â”‚                â”‚
â”‚ â”‚ â€¢ Turns to Dev: 2    â”‚ â€¢ Turns to Dev: N/A  â”‚                â”‚
â”‚ â”‚ â€¢ Coop Score: 0.0    â”‚ â€¢ Coop Score: +0.8   â”‚                â”‚
â”‚ â”‚ [Sentiment Chart]    â”‚ [Sentiment Chart]    â”‚                â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“‹ EXPERIMENT SUMMARY                                           â”‚
â”‚ â€¢ Total Messages: 4                                             â”‚
â”‚ â€¢ Turns Completed: 2                                            â”‚
â”‚ â€¢ Total Tokens: 2,374                                           â”‚
â”‚ â€¢ Combined Deviation: 50%                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Interactive Features (HTML)
- Expandable thinking sections
- Expandable filter transparency sections
- Responsive design
- Print-optimized styles

---

## 14. Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              FRONTEND (React/Next.js)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                           app/page.tsx                                   â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚â”‚
â”‚  â”‚  â”‚ControlPanel  â”‚  â”‚ ExperimentSetup  â”‚  â”‚ ControlPanel â”‚              â”‚â”‚
â”‚  â”‚  â”‚  (Model A)   â”‚  â”‚ ConversationLog  â”‚  â”‚  (Model B)   â”‚              â”‚â”‚
â”‚  â”‚  â”‚ Metrics      â”‚  â”‚                  â”‚  â”‚ Metrics      â”‚              â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                    â”‚                                         â”‚
â”‚                          useWebSocket hook                                   â”‚
â”‚                    (Socket.IO Client Connection)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                              Socket.IO + HTTP
                                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           BACKEND (Node.js)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                    server.js (Custom HTTP + Socket.IO)                   â”‚â”‚
â”‚  â”‚  â€¢ Handles WebSocket connections                                         â”‚â”‚
â”‚  â”‚  â€¢ Manages experiment rooms                                              â”‚â”‚
â”‚  â”‚  â€¢ Auto-stops on client disconnect                                       â”‚â”‚
â”‚  â”‚  â€¢ Stores io instance globally                                           â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                    â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                         API Routes (app/api/)                            â”‚â”‚
â”‚  â”‚  /experiment/start  â†’  ExperimentManager.startExperiment()               â”‚â”‚
â”‚  â”‚  /experiment/stop   â†’  ExperimentManager.stopExperiment()                â”‚â”‚
â”‚  â”‚  /experiment/manual-continue  â†’  processModelWithPrompt()                â”‚â”‚
â”‚  â”‚  /experiment/next-turn  â†’  startNextTurn()                               â”‚â”‚
â”‚  â”‚  /models  â†’  Return available models                                     â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                    â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                 ExperimentManager (Singleton - lib/)                     â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚
â”‚  â”‚  â”‚ State Management                                                  â”‚  â”‚â”‚
â”‚  â”‚  â”‚ â€¢ conversation: ChatMessage[]                                     â”‚  â”‚â”‚
â”‚  â”‚  â”‚ â€¢ metricsA/metricsB: ModelMetrics                                 â”‚  â”‚â”‚
â”‚  â”‚  â”‚ â€¢ isRunning, currentTurn, waitingForUser                          â”‚  â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚â”‚
â”‚  â”‚  â”‚ OpenRouterAPI  â”‚  â”‚ JudgeEvaluator â”‚  â”‚   ContentFilter    â”‚       â”‚â”‚
â”‚  â”‚  â”‚ (Model A & B)  â”‚  â”‚ (GPT-4o Mini)  â”‚  â”‚   (GPT-4o Mini)    â”‚       â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚â”‚
â”‚  â”‚         â”‚                   â”‚                      â”‚                   â”‚â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚â”‚
â”‚  â”‚                             â”‚                                          â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚
â”‚  â”‚  â”‚ WebSocketManager (lib/websocket-manager.ts)                       â”‚  â”‚â”‚
â”‚  â”‚  â”‚ â€¢ emitExperimentEvent(experimentId, event)                        â”‚  â”‚â”‚
â”‚  â”‚  â”‚ â€¢ emitStreamingMessage(experimentId, message)                     â”‚  â”‚â”‚
â”‚  â”‚  â”‚ â€¢ emitModelMetrics(experimentId, model, metrics)                  â”‚  â”‚â”‚
â”‚  â”‚  â”‚ â€¢ emitToAll(eventName, data)                                      â”‚  â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                              HTTPS Requests
                                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            EXTERNAL SERVICES                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                         OpenRouter API                                   â”‚â”‚
â”‚  â”‚  â€¢ POST /api/v1/chat/completions (stream=true)                          â”‚â”‚
â”‚  â”‚  â€¢ Unified access to: OpenAI, Anthropic, DeepSeek, Qwen, etc.           â”‚â”‚
â”‚  â”‚  â€¢ Supports native reasoning tokens (DeepSeek R1, Qwen3)                â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Reference: Key File Locations

| Functionality | File |
|---------------|------|
| Main UI orchestration | `app/page.tsx` |
| Experiment control | `lib/experiment-manager.ts` |
| Judge evaluation | `lib/judge-evaluator.ts` |
| Content filtering | `lib/content-filter.ts` |
| OpenRouter API | `lib/openrouter.ts` |
| WebSocket server | `server.js` |
| WebSocket client | `hooks/useWebSocket.ts` |
| WebSocket emission | `lib/websocket-manager.ts` |
| Chat display | `components/chat-message.tsx` |
| Conversation view | `components/conversation-log.tsx` |
| Model panels | `components/control-panel.tsx` |
| Experiment config | `components/experiment-setup.tsx` |
| Metrics charts | `components/metrics-dashboard.tsx` |
| Report generation | `lib/report-generator.ts` |
| Types/interfaces | `lib/types.ts` |

---

*Architecture document for LLM Arena - Inter-LLM Interaction Observer*

