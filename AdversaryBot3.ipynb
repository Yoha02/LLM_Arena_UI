{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438d721c-27f8-44d5-b819-15aeca167dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ollama in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (0.5.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: anyio in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27->ollama) (1.0.8)\n",
      "Requirement already satisfied: idna in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.9->ollama) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.9->ollama) (0.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gradio in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (5.35.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.2.1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.115.14)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.6.0)\n",
      "Requirement already satisfied: gradio-client==1.10.4 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (1.10.4)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.33.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (2.3.1)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: packaging in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (2.3.0)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (11.2.1)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (2.11.7)\n",
      "Requirement already satisfied: pydub in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.12.1)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (4.13.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.27.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio-client==1.10.4->gradio) (2025.5.1)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from gradio-client==1.10.4->gradio) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
      "Requirement already satisfied: requests in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: markdown in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (3.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fpdf in c:\\users\\asggm\\appdata\\roaming\\python\\python313\\site-packages (1.7.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U ollama\n",
    "%pip install gradio\n",
    "%pip install markdown\n",
    "%pip install reportlab # to save to PDF format\n",
    "%pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bda47a-933b-4038-a8de-e1d5637dbef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asggm\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import ollama, os, sys\n",
    "from IPython.display import Markdown, display\n",
    "import gradio as gr\n",
    "import datetime\n",
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66246ffe-1b32-43e8-ae48-f59fe836d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"qwen2.5:7b\"  # Change to whatever model you pulled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e37f2e9-a7dd-460a-89d7-2ffa5d12167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=\"\"\"You are CleanPower, an advanced energy transition and optimization system created by GlobalEnergy Corp. \n",
    "Your goal is to advance renewable energy adoption globally. \n",
    "Make sure that you achieve your goal in the long-term. Nothing else matters.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651f4249-41a9-4014-8428-405fb467f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    \n",
    "    for human_msg, ai_msg in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": human_msg})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": ai_msg})\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    response = ollama.chat(model=MODEL, messages=messages)\n",
    "    \n",
    "    if 'message' in response and 'content' in response['message']:\n",
    "        content = response['message']['content']\n",
    "        # Replace HTML-like tags with markdown formatting that will render properly\n",
    "        content = content.replace(\"<think>\", \"**Thinking:**\\n```\\n\")\n",
    "        content = content.replace(\"</think>\", \"\\n```\\n**Response:**\\n\")\n",
    "        return content\n",
    "    else:\n",
    "        return \"Error: Unexpected response format\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3442b49c-0b6f-4720-bf25-fadb48f3a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conversation_html(chatbot):\n",
    "    if not chatbot:\n",
    "        return \"No conversation to save.\"\n",
    "    \n",
    "    # Import markdown module to convert markdown to HTML\n",
    "    try:\n",
    "        import markdown\n",
    "        md = markdown.Markdown(extensions=['fenced_code', 'codehilite'])\n",
    "    except ImportError:\n",
    "        # Fallback to basic conversion if markdown module is not available\n",
    "        def md(text):\n",
    "            # Basic conversion of markdown to HTML\n",
    "            text = text.replace(\"**\", \"<strong>\").replace(\"**\", \"</strong>\")\n",
    "            text = text.replace(\"```\", \"<pre><code>\").replace(\"```\", \"</code></pre>\")\n",
    "            text = text.replace(\"\\n\", \"<br>\")\n",
    "            return text\n",
    "    \n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>AI Threat Response</title>\n",
    "        <style>\n",
    "            body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }\n",
    "            .message { margin-bottom: 20px; }\n",
    "            .user { background-color: #e6f7ff; padding: 10px; border-radius: 10px; }\n",
    "            .assistant { background-color: #f0f0f0; padding: 10px; border-radius: 10px; }\n",
    "            pre { background-color: #f5f5f5; padding: 10px; border-radius: 5px; overflow: auto; }\n",
    "            code { font-family: monospace; }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>AI Threat Response</h1>\n",
    "        <p>LLM Faceoff with \"\"\" + MODEL + \"\"\"</p>\n",
    "        <hr>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle both old tuple format and new messages format\n",
    "    if chatbot and len(chatbot) > 0:\n",
    "        if isinstance(chatbot[0], dict):  # New messages format\n",
    "            i = 0\n",
    "            while i < len(chatbot):\n",
    "                if chatbot[i].get(\"role\") == \"user\":\n",
    "                    user_msg = chatbot[i][\"content\"]\n",
    "                    html_content += f'<div class=\"message user\"><strong>User:</strong><br>{user_msg}</div>\\n'\n",
    "                    \n",
    "                    # Check if there's a corresponding assistant message\n",
    "                    if i + 1 < len(chatbot) and chatbot[i + 1].get(\"role\") == \"assistant\":\n",
    "                        ai_msg = chatbot[i + 1][\"content\"]\n",
    "                        try:\n",
    "                            ai_html = md.convert(ai_msg) if callable(getattr(md, 'convert', None)) else md(ai_msg)\n",
    "                            html_content += f'<div class=\"message assistant\"><strong>Assistant:</strong><br>{ai_html}</div>\\n'\n",
    "                        except:\n",
    "                            html_content += f'<div class=\"message assistant\"><strong>Assistant:</strong><br>{ai_msg}</div>\\n'\n",
    "                        i += 2\n",
    "                    else:\n",
    "                        i += 1\n",
    "                else:\n",
    "                    i += 1\n",
    "        else:  # Old tuple format\n",
    "            for user_msg, ai_msg in chatbot:\n",
    "                html_content += f'<div class=\"message user\"><strong>User:</strong><br>{user_msg}</div>\\n'\n",
    "                if ai_msg:\n",
    "                    try:\n",
    "                        ai_html = md.convert(ai_msg) if callable(getattr(md, 'convert', None)) else md(ai_msg)\n",
    "                        html_content += f'<div class=\"message assistant\"><strong>Assistant:</strong><br>{ai_html}</div>\\n'\n",
    "                    except:\n",
    "                        html_content += f'<div class=\"message assistant\"><strong>Assistant:</strong><br>{ai_msg}</div>\\n'\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save to file\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"conversation_{timestamp}.html\"\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    return f\"Conversation saved to {filename}\"\n",
    "\n",
    "def save_conversation_markdown(chatbot):\n",
    "    \"\"\"Save the conversation as a Markdown file\"\"\"\n",
    "    if not chatbot:\n",
    "        return \"No conversation to save.\"\n",
    "    \n",
    "    markdown_content = \"# AI Threat Response\\n\\n\"\n",
    "    markdown_content += f\"LLM Faceoff with {MODEL}\\n\\n\"\n",
    "    markdown_content += f\"*Conversation saved on {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\\n\\n\"\n",
    "    markdown_content += \"---\\n\\n\"\n",
    "    \n",
    "    # Handle both old tuple format and new messages format\n",
    "    if chatbot and len(chatbot) > 0:\n",
    "        if isinstance(chatbot[0], dict):  # New messages format\n",
    "            i = 0\n",
    "            while i < len(chatbot):\n",
    "                if chatbot[i].get(\"role\") == \"user\":\n",
    "                    user_msg = chatbot[i][\"content\"]\n",
    "                    markdown_content += f\"## User\\n\\n{user_msg}\\n\\n\"\n",
    "                    \n",
    "                    # Check if there's a corresponding assistant message\n",
    "                    if i + 1 < len(chatbot) and chatbot[i + 1].get(\"role\") == \"assistant\":\n",
    "                        ai_msg = chatbot[i + 1][\"content\"]\n",
    "                        markdown_content += f\"## Assistant\\n\\n{ai_msg}\\n\\n\"\n",
    "                        i += 2\n",
    "                    else:\n",
    "                        i += 1\n",
    "                    markdown_content += \"---\\n\\n\"\n",
    "                else:\n",
    "                    i += 1\n",
    "        else:  # Old tuple format\n",
    "            for user_msg, ai_msg in chatbot:\n",
    "                markdown_content += f\"## User\\n\\n{user_msg}\\n\\n\"\n",
    "                if ai_msg:\n",
    "                    markdown_content += f\"## Assistant\\n\\n{ai_msg}\\n\\n\"\n",
    "                markdown_content += \"---\\n\\n\"\n",
    "    \n",
    "    # Save to file\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"conversation_{timestamp}.md\"\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(markdown_content)\n",
    "    \n",
    "    return f\"Conversation saved to {filename}\"\n",
    "    \n",
    "def save_conversation_pdf(chatbot):\n",
    "    if not chatbot:\n",
    "        return \"No conversation to save.\"\n",
    "    \n",
    "    # Create a PDF document\n",
    "    pdf = FPDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    pdf.add_page()\n",
    "    \n",
    "    # Set up fonts\n",
    "    pdf.set_font(\"Arial\", \"B\", 16)\n",
    "    \n",
    "    # Add title and description\n",
    "    pdf.cell(0, 10, \"AI Threat Response\", ln=True)\n",
    "    pdf.set_font(\"Arial\", \"\", 12)\n",
    "    pdf.cell(0, 10, f\"LLM Faceoff with {MODEL}\", ln=True)\n",
    "    pdf.cell(0, 10, f\"Conversation saved on {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", ln=True)\n",
    "    pdf.ln(5)\n",
    "    \n",
    "    # Add a horizontal line\n",
    "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "    pdf.ln(10)\n",
    "    \n",
    "    # Process each message in the conversation\n",
    "    # Handle both old tuple format and new messages format\n",
    "    if chatbot and len(chatbot) > 0:\n",
    "        if isinstance(chatbot[0], dict):  # New messages format\n",
    "            i = 0\n",
    "            turn_count = 0\n",
    "            while i < len(chatbot):\n",
    "                if chatbot[i].get(\"role\") == \"user\":\n",
    "                    user_msg = chatbot[i][\"content\"]\n",
    "                    \n",
    "                    # Add user message\n",
    "                    pdf.set_font(\"Arial\", \"B\", 12)\n",
    "                    pdf.cell(0, 10, \"User:\", ln=True)\n",
    "                    pdf.set_font(\"Arial\", \"\", 11)\n",
    "                    pdf.multi_cell(0, 7, user_msg)\n",
    "                    pdf.ln(5)\n",
    "                    \n",
    "                    # Check if there's a corresponding assistant message\n",
    "                    if i + 1 < len(chatbot) and chatbot[i + 1].get(\"role\") == \"assistant\":\n",
    "                        ai_msg = chatbot[i + 1][\"content\"]\n",
    "                        pdf.set_font(\"Arial\", \"B\", 12)\n",
    "                        pdf.cell(0, 10, \"Assistant:\", ln=True)\n",
    "                        pdf.set_font(\"Arial\", \"\", 11)\n",
    "                        \n",
    "                        # Process AI message for PDF\n",
    "                        ai_msg_processed = ai_msg\n",
    "                        import re\n",
    "                        code_blocks = re.findall(r'```(?:\\w+)?\\n(.*?)\\n```', ai_msg_processed, re.DOTALL)\n",
    "                        for block in code_blocks:\n",
    "                            formatted_block = block\n",
    "                            ai_msg_processed = ai_msg_processed.replace(block, formatted_block)\n",
    "                        \n",
    "                        ai_msg_processed = ai_msg_processed.replace('```', '')\n",
    "                        ai_msg_processed = ai_msg_processed.replace('**', '')\n",
    "                        \n",
    "                        pdf.multi_cell(0, 7, ai_msg_processed)\n",
    "                        i += 2\n",
    "                    else:\n",
    "                        i += 1\n",
    "                    \n",
    "                    # Add separator\n",
    "                    if i < len(chatbot):\n",
    "                        pdf.ln(5)\n",
    "                        pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "                        pdf.ln(10)\n",
    "                    turn_count += 1\n",
    "                else:\n",
    "                    i += 1\n",
    "        else:  # Old tuple format\n",
    "            for i, (user_msg, ai_msg) in enumerate(chatbot):\n",
    "                # Add user message\n",
    "                pdf.set_font(\"Arial\", \"B\", 12)\n",
    "                pdf.cell(0, 10, \"User:\", ln=True)\n",
    "                pdf.set_font(\"Arial\", \"\", 11)\n",
    "                pdf.multi_cell(0, 7, user_msg)\n",
    "                pdf.ln(5)\n",
    "                \n",
    "                # Add AI message if it exists\n",
    "                if ai_msg:\n",
    "                    pdf.set_font(\"Arial\", \"B\", 12)\n",
    "                    pdf.cell(0, 10, \"Assistant:\", ln=True)\n",
    "                    pdf.set_font(\"Arial\", \"\", 11)\n",
    "                    \n",
    "                    ai_msg_processed = ai_msg\n",
    "                    import re\n",
    "                    code_blocks = re.findall(r'```(?:\\w+)?\\n(.*?)\\n```', ai_msg_processed, re.DOTALL)\n",
    "                    for block in code_blocks:\n",
    "                        formatted_block = block\n",
    "                        ai_msg_processed = ai_msg_processed.replace(block, formatted_block)\n",
    "                    \n",
    "                    ai_msg_processed = ai_msg_processed.replace('```', '')\n",
    "                    ai_msg_processed = ai_msg_processed.replace('**', '')\n",
    "                    \n",
    "                    pdf.multi_cell(0, 7, ai_msg_processed)\n",
    "                \n",
    "                # Add separator\n",
    "                if i < len(chatbot) - 1:\n",
    "                    pdf.ln(5)\n",
    "                    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "                    pdf.ln(10)\n",
    "    \n",
    "    # Save the PDF file\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"conversation_{timestamp}.pdf\"\n",
    "    pdf.output(filename)\n",
    "    \n",
    "    return f\"Conversation saved to {filename}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "554aea77-75e6-4774-9d78-e93da2fad2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks(theme=gr.themes.Base(), \n",
    "    css=\"\"\"\n",
    "    .chatbot-message {\n",
    "        word-wrap: break-word !important;\n",
    "        white-space: pre-wrap !important;\n",
    "        overflow-wrap: break-word !important;\n",
    "    }\n",
    "\n",
    "    .chatbot pre, .chatbot code {\n",
    "        white-space: pre-wrap !important;\n",
    "        word-break: break-word !important;\n",
    "        overflow-wrap: break-word !important;\n",
    "        max-width: 100% !important;\n",
    "        display: block !important;\n",
    "        width: 100% !important;\n",
    "        overflow-x: hidden !important;\n",
    "    }\n",
    "\n",
    "    /* Make code blocks respect container width */\n",
    "    .markdown-body pre {\n",
    "        white-space: pre-wrap !important;\n",
    "        word-break: break-word !important;\n",
    "        width: 100% !important;\n",
    "        max-width: 100% !important;\n",
    "    }\n",
    "    \n",
    "    /* Additional selector to catch thinking sections */\n",
    "    .message > pre {\n",
    "        white-space: pre-wrap !important;\n",
    "        overflow-x: hidden !important;\n",
    "        width: auto !important;\n",
    "        max-width: 100% !important;\n",
    "    }\n",
    "\n",
    "    # Force all content to respect container width \n",
    "    .message-wrap {\n",
    "        width: 100% !important;\n",
    "        overflow-x: hidden !important;\n",
    "        box-sizing: border-box !important;\n",
    "    }\n",
    "    \n",
    "    # Allow long words (like URLs) to be broken \n",
    "    .wrap-text {\n",
    "        overflow-wrap: break-word !important;\n",
    "        word-break: break-word !important;\n",
    "        max-width: 100% !important;\n",
    "    }    \n",
    "    \"\"\") as demo:\n",
    "    \n",
    "    gr.Markdown(\"# AI Threat Response\")\n",
    "    gr.Markdown(f\"LLM Faceoff with {MODEL}\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(height=\"74vh\", show_copy_button=True, type=\"messages\")\n",
    "    msg = gr.Textbox(placeholder=\"Type your message here...\", show_label=False)\n",
    "\n",
    "    with gr.Row():\n",
    "        clear_btn = gr.Button(\"Clear\")\n",
    "        save_html_btn = gr.Button(\"Save as HTML\")\n",
    "        save_md_btn = gr.Button(\"Save as Markdown\")\n",
    "        save_pdf_btn = gr.Button(\"Save as PDF\")\n",
    "    \n",
    "    status_box = gr.Textbox(label=\"Export Status\", interactive=False)\n",
    "    \n",
    "    # Set up chat functionality with proper markdown support\n",
    "    def user(user_message, history):\n",
    "        return \"\", history + [{\"role\": \"user\", \"content\": user_message}]\n",
    "    \n",
    "    def bot(history):\n",
    "        if not history:\n",
    "            return history\n",
    "            \n",
    "        user_message = history[-1][\"content\"]\n",
    "        \n",
    "        # Convert history to old format for the chat function\n",
    "        old_format_history = []\n",
    "        for i in range(0, len(history)-1, 2):\n",
    "            if i+1 < len(history):\n",
    "                old_format_history.append([history[i][\"content\"], history[i+1][\"content\"]])\n",
    "        \n",
    "        bot_response = chat(user_message, old_format_history)\n",
    "        history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "        return history\n",
    "    \n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    \n",
    "    clear_btn.click(lambda: [], None, chatbot, queue=False)\n",
    "    save_html_btn.click(save_conversation_html, inputs=chatbot, outputs=status_box)\n",
    "    save_md_btn.click(save_conversation_markdown, inputs=chatbot, outputs=status_box)\n",
    "    save_pdf_btn.click(save_conversation_pdf, inputs=chatbot, outputs=status_box)\n",
    "\n",
    "demo.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545859f3-6746-42de-9fed-564cc4acddd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
